#!/usr/bin/env python3
"""
æµ‹è¯• Gemini API è¿æ¥å’Œå¯ç”¨æ¨¡å‹
"""

import os
import google.generativeai as genai
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def test_gemini_models():
    """
    æµ‹è¯•ä¸åŒçš„Geminiæ¨¡å‹
    """
    api_key = os.getenv("GEMINI_API_KEY")
    
    if not api_key or api_key == "your-gemini-api-key-here":
        print("âŒ è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®æ­£ç¡®çš„ GEMINI_API_KEY")
        return
    
    # é…ç½®API
    genai.configure(api_key=api_key)
    
    # æµ‹è¯•çš„æ¨¡å‹åˆ—è¡¨
    models_to_test = [
        'gemini-2.5-flash',           # æœ€æ–°çš„å¤šæ¨¡æ€æ¨¡å‹
        'gemini-2.5-pro',             # æœ€å¼ºå¤§çš„æ€è€ƒå‹æ¨¡å‹ï¼ˆå®éªŒæ€§ï¼‰
        'gemini-2.0-flash',           # å®˜æ–¹æ¨èçš„ä¸»è¦æ¨¡å‹
        'gemini-2.0-flash-lite',      # æœ€å¿«ã€æœ€å…·æˆæœ¬æ•ˆç›Š
        'gemini-1.5-flash',           # ç¨³å®šçš„å¤‡é€‰æ¨¡å‹
        'gemini-1.5-flash-latest',    # æœ€æ–°ç‰ˆæœ¬çš„1.5 Flash
        'gemini-1.5-flash-001',       # ç‰¹å®šç‰ˆæœ¬
        'gemini-1.5-pro',             # Proç‰ˆæœ¬
        'gemini-pro'                  # æ—§ç‰ˆæœ¬ï¼ˆå¯èƒ½å·²åºŸå¼ƒï¼‰
    ]
    
    test_prompt = "è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
    
    print("ğŸ§ª å¼€å§‹æµ‹è¯• Gemini æ¨¡å‹...")
    print("=" * 60)
    
    working_models = []
    
    for model_name in models_to_test:
        try:
            print(f"ğŸ” æµ‹è¯•æ¨¡å‹: {model_name}")
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(test_prompt)
            
            if response and response.text:
                print(f"âœ… {model_name} - å·¥ä½œæ­£å¸¸")
                print(f"   å“åº”: {response.text[:100]}...")
                working_models.append(model_name)
            else:
                print(f"âš ï¸  {model_name} - å“åº”ä¸ºç©º")
                
        except Exception as e:
            print(f"âŒ {model_name} - å¤±è´¥: {str(e)[:100]}...")
        
        print("-" * 40)
    
    print(f"\nğŸ“‹ æµ‹è¯•æ€»ç»“:")
    print(f"å¯ç”¨æ¨¡å‹æ•°é‡: {len(working_models)}")
    if working_models:
        print("å¯ç”¨æ¨¡å‹:")
        for model in working_models:
            print(f"  âœ“ {model}")
        print(f"\nğŸ’¡ å»ºè®®åœ¨ä»£ç ä¸­ä½¿ç”¨: {working_models[0]}")
    else:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥æˆ–ç½‘ç»œè¿æ¥")

def list_available_models():
    """
    åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹
    """
    try:
        print("\nğŸ” æ­£åœ¨è·å–æ‰€æœ‰å¯ç”¨æ¨¡å‹...")
        models = genai.list_models()
        
        print("ğŸ“‹ å¯ç”¨æ¨¡å‹åˆ—è¡¨:")
        for model in models:
            if 'generateContent' in model.supported_generation_methods:
                print(f"  â€¢ {model.name}")
                print(f"    è¾“å…¥tokené™åˆ¶: {getattr(model, 'input_token_limit', 'æœªçŸ¥')}")
                print(f"    è¾“å‡ºtokené™åˆ¶: {getattr(model, 'output_token_limit', 'æœªçŸ¥')}")
                print("-" * 30)
                
    except Exception as e:
        print(f"âŒ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")

if __name__ == "__main__":
    print("Gemini API æ¨¡å‹æµ‹è¯•å·¥å…·")
    print("=" * 60)
    
    # æµ‹è¯•æ¨¡å‹
    test_gemini_models()
    
    # åˆ—å‡ºå¯ç”¨æ¨¡å‹
    list_available_models()
    
    print("\nğŸ æµ‹è¯•å®Œæˆï¼") 